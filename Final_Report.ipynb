{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Default Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this project is to identify if individuals will default or re-pay loans back based on many different factors. Many individial with little or no credit history are either rejected when they apply for a loan or they are being taken advantage of by re-paying the loan with extremely high interest rates. I will use data such as credit card balance, age, job title, annual pay, education to examine if clients are capable of repaying their loans based on those factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Home Credit is an international consumer finance provider with operations in 9 countries.  The data from Home Credit Default Risk Kaggle competition will be used for this capstone. The Kaggle competition for Home Credit default risk can be found [here](https://www.kaggle.com/c/home-credit-default-risk/data).   There following 7 tables were available from Home Credit.  Below is a general overview of each table:\n",
    "\n",
    "- application_{train|test}.csv\n",
    "    - This is the main table, broken into two files for Train (with TARGET) and Test (without TARGET).\n",
    "Static data for all applications. One row represents one loan in our data sample.\n",
    "\n",
    "- bureau.csv\n",
    "    - All client's previous credits provided by other financial institutions that were reported to Credit Bureau (for clients who have a loan in our sample).\n",
    "\n",
    "- bureau_balance.csv\n",
    "    - Monthly balances of previous credits in Credit Bureau.\n",
    "\n",
    "- POS_CASH_balance.csv\n",
    "    - Monthly balance snapshots of previous POS (point of sales) and cash loans that the applicant had with Home Credit.\n",
    "\n",
    "- credit_card_balance.csv\n",
    "    - Monthly balance snapshots of previous credit cards that the applicant has with Home Credit.\n",
    "\n",
    "- previous_application.csv\n",
    "    - All previous applications for Home Credit loans of clients who have loans in our sample.\n",
    "\n",
    "- installments_payments.csv\n",
    "    - Repayment history for the previously disbursed credits in Home Credit related to the loans in our sample.\n",
    "    \n",
    "For this project I started by cleaning and exploring the data in the application_train.csv file since it contains so much data about each applicant and I wanted to explore the difference between using simple features such as the age of the applicant, total credit loaned, total credit payed off, if the applicant is a home_owner, education level.  Initially I used only the data in the application_train.csv and then I added data from bureau.csv and other engineered data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon loading the data the application dataframe has 307511 entries/applications and 122 columns (features). And the burea dataframe has 1,716,427 entries and 17 columns.\n",
    "I started by examining the quality of the data by using .describe(), and checking the percentage of missing values/column. \n",
    "\n",
    "Even though some features are not required to apply and get approved for a loan (such as if the house you live in brick or not), I am curious whether those features will improve or worsen our predictions. I will prepare be using the dataset (using the same models) in 3 different ways:\n",
    "1. the application dataframe only, without removing any columns and imputing the missing values.\n",
    "2. drop the features (columns) that are not important or required.\n",
    "3. add new features from the burea dataframe and examine if engineered features will help different models in providing more accurate results. \n",
    "\n",
    "Below is a summary of the main steps I took to clean the main issues I found:\n",
    "- **Number of years columns:** All the columns with data regarding number of years were in a negative value in days - for instance the age column for an applicant who is 20 years old is available as -7300.\n",
    " - Divided the number of days by 365 \n",
    " - Took the absoloute value of each result from the previous step\n",
    "- **Missing values:** There are 122 columns in total in the application dataframe, 49 columns contained beween 48% and 69% null values. I decided to ask an expert in the field which of these columns are actually requirded while evaluating if an individual will be granted a loan or not.  It was concluded that the 49 columns are in fact not needed.\n",
    " - 49 columns were droped from the data.\n",
    " - The mean or median was be imputed for columns with 45% or less missing values. \n",
    "- **Outliers:** Some values were definetly wrong (such as YEARS_EMPLOYED=1000.7 years)\n",
    "    - There were 55374 observations where the years employed is 1000.7 years.\n",
    "    - Extremely high values were replaced by the median - such an applicant having 19 children\n",
    "    - YEARS_EMPLOYED contains a value of 1000.7 years - this row was deleted\n",
    "- **Reduce number of columns:** There are 20 columns that flag whether a documnt has been submitted or now (1 for submitted and 0 for not).  The sum of all of those columns will be added with a new column (TOTAL_DOCUMENTS).\n",
    "    - Deleted 20 columns FLAG_DOCUMENT_2 to FLAG_DOCUMENT_21\n",
    "- **Categorial Variables:** \n",
    "    - 31.5% of OCCUPATION_TYPE were missing values, imputed the most occuring category ('Laborers').\n",
    "    - 4 rows contained 'XNA' as Gender type, those rows were deleted.\n",
    "    - 0.42% of NAME_TYPE_SUITE were missing values, imputed the mode.\n",
    "    \n",
    "- After discussing my project with a domain expert in finance, it was concluded that alot of the features are neither needed not required by financial insustutions to apply for a loan.  I was still curious to see if those features would affect the prediction model positively or negatively. So I decided to use 2 different dataframes for this project:\n",
    "    - The first data frame will include all 122 features and I imputed all the missing values using simple imputer. \n",
    "    - The second data frame will have only those features that are in fact required when applying for a loan - which ended up being 53 columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Distribution of paid vs. unpaid loans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of the EDA for this project is to take a closer look at the distribution of paid and unpaid loans.  In Figure 1 we can see that 91.9% of the loans are paid, while only 8.1% is unpaid. Going forward we'll take a closer look at features that may influence unpaid loans. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary of Findings:\n",
    "- 91.9% of Loans are paid back while 8.1% of the applicants fail to pay their loans back. (Figure 1)\n",
    "- Based on our Target (0 = Paid and 1 = Unpaid Loan), there is an imbalance with the data.\n",
    "- Females represent 65.8% of applicants and 34.2% are males.\n",
    "    - 4.6% of females fail to pay the loan back (7.5% of the total female population default on the loan)\n",
    "    - 3.5% of males fail to pay the loan back (11.4% of the total male population default on the loan)\n",
    "- 70% of applicants don't have any children and 19.9% have 1 child, 8.7% have 2 children\n",
    "    - applicants who don't have childred represent 66.6% of unpaid loans (5.4% of the total population - paid and unpaid)\n",
    "- 90.6% of loans are cash loans, while 9.4% are revolving loans\n",
    "    - 7.6% of unpaid loans are cash loans while 0.5% are revolving loans\n",
    "- 49.3% of applicants have an occupation type of Laborers, 10.4% are 'sales staff' and 9.0% are 'core staff'\n",
    "- 71.1% of applicants hold a seconday education and 24.3% have higher education.\n",
    "    - secondary education holders represent 6.3% of unpaid loans (highest) but they also hold the highest number of total applications. \n",
    "- 69.4% of applicants are realty owners while 66% of applicants don't own a car. \n",
    "- There is a strong correlation between the amount of credit an applicant applies for and the price of good they are buying using the loan. \n",
    "- The three variable with the strongest negative correlation with TARGET are EXT_SOURCE1, 2 and 3 and TARGET - meaning as the EXT_SOURCE increases the unpaid loans decrease. According to the documentation EXT_SOURCE represent a \"normalized score from external data source\". \n",
    "    - Taking the mean of the 3 EXT_SOURCE variables shows a greater negative correlation of 0.22.\n",
    "- Age has a big impact loan repayment, younger applicants are more likely to fail in paying the loans back. As the applicant's age increases, the percentage of non-payment significantly decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ![Distribution paid and unpaid loans](Charts/PaidUnpaid1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Loan Distribution by Gender](Charts/PaidUnpaidByGender.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Distribution_EXT_SOURCES](Charts/EXT_KDE2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ![Failure to pay age groups](Charts/age.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For data preprocessing a few steps were taken:\n",
    " - Created a new dataframe to hold all columns with data type \"OBJECT\"\n",
    " - Created a new dataframe to hold all numerical values (inorder to scale them)\n",
    " - Created a new dataframe to hold all flags (flags are numerical values but they don't need to be scaled)\n",
    " - Used SimpleImputer to impute any NaN values that I might have missed during the cleaning process \n",
    " - Use MinMax scaler to scale the data - there were too many values in different scales (such as income, age, number of children)\n",
    " - Used get_dummies to transform categorial variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be using 2 different datafames for the prediction of our model and I will test 3 different algorithms to determine whether the algorithm provides better predictions with more features (122 features) or with less features (53 features):\n",
    "    1. Logistic regression\n",
    "    2. Gradient Boosting\n",
    "    3. Random Forest\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.1 Logistic Regression with 122 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the logistic regression model on the test set was 49%, which is pretty low.  When I looked further to analyze the findings, it seems like the model didn't predict any Target=1 values.  Even though the data is balanced, I am not sure why none of the unpaid loans were predicted. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![logistic regression report](Charts/logReg1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![logistic regression ROC](Charts/logReg1-ROC.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.2 Logistic Regression with 53 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results with reduced columns is exactly the same as the results found above with the complete dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![logistic regression report](Charts/logReg2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![logistic regression ROC](Charts/logReg2-ROC.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.1 Gradient boosting with 122 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score for gradient boosting is 61.4% - which is a much better performance than the logistic regression model, however the results are still not accurate enough. \n",
    "\n",
    "Accuracy score (training): 0.623\n",
    "\n",
    "Accuracy score (validation): 0.614\n",
    "\n",
    "Accuracy: 0.614"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Gradient boosting ROC](Charts/GB-ROC2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.2 Gradient boosting with 53 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score for gradient boosting is 62.3% - which is a much better performance than the logistic regression model, however the results are still not accurate enough.  \n",
    "\n",
    "Accuracy score (training): 0.629\n",
    "\n",
    "Accuracy score (validation): 0.623\n",
    "\n",
    "Accuracy: 0.623"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Gradient boosting ROC](Charts/GB-ROC1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance for the GB model is slightly better with less features - accuracy score increase from 61.4% to 62.3%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.1 Random Forest with 122 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far this is the best performing model with 68.2% accuracy score and ROC curve area is 0.742.\n",
    "\n",
    "Random Forest: Accuracy=0.682\n",
    "\n",
    "Random Forest: f1-score=0.682"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Randome Forest ROC](Charts/RF_ROC1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.2 Random Forest with 53 Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy with the reduced columns is exactly the same as the accurracy with the 122 features dataset.  \n",
    "\n",
    "Random Forest: Accuracy=0.682\n",
    "\n",
    "Random Forest: f1-score=0.682"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Random Forest ROC](Charts/RF_ROC2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.0 Variable Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both models for random forest were the best performing models.  However, both models had EXT_Source3 and EXT_Source2 to be the variable with the highest importance.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Variable Importance](Charts/RF_Var_importance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.0 Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a user interface where users are able to enter their information (age, income, total owing credit, number of active loans, years of employment) and get a prediction of the likelihood of defaulting on a loan.\n",
    "- Filter the datasets and remove EXT_SOURCE and check performance.\n",
    "- Use the dataset with added engineered features and check whether the accuracy increases or decreases. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
